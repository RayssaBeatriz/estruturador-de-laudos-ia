# ğŸ—ï¸ Mammo RAG Local

Projeto de Processamento de Linguagem Natural (NLP) com **DeepSeek** e **LangChain** para extrair dados estruturados (BI-RADS e Lateralidade) de laudos de mamografia. O cÃ³digo foi modularizado para garantir total privacidade e execuÃ§Ã£o local.

## ğŸ“‚ Estrutura

* `main.py`: Script principal para execuÃ§Ã£o (Menu CLI).
* `ingestion.py`: Leitura de PDFs, chunking e vetorizaÃ§Ã£o no banco de dados.
* `rag_engine.py`: Motor de RAG (Chat e ExtraÃ§Ã£o) conectado ao LLM local.
* `vector_store.py`: Gerenciamento do banco vetorial (ChromaDB) e embeddings.
* `models.py`: DefiniÃ§Ã£o dos schemas de dados (JSON/Pydantic).

## ğŸ›  Tecnologias

`Python` | `LangChain` | `Ollama (DeepSeek)` | `ChromaDB` | `HuggingFace`

## ğŸš€ Como Executar

1.  **Clone o repositÃ³rio:**
    ```bash
    git clone https://github.com/RayssaBeatriz/estruturador-de-laudos-ia
    cd estruturador-de-laudos-ia
    ```

2.  **Prepare o modelo local:**
    Certifique-se de ter o [Ollama](https://ollama.com) instalado e baixe o modelo:
    ```bash
    ollama pull deepseek-r1:7b
    ```

3.  **Instale as dependÃªncias:**
    ```bash
    python -m venv .venv
    .\.venv\Scripts\Activate.ps1
    pip install -r requirements.txt
    ```

4.  **Rode o projeto:**
    ```bash
    python main.py
    ```

## ğŸ“Š Modelo e Resultados

O sistema utiliza uma arquitetura **RAG (Retrieval-Augmented Generation)** rodando 100% localmente. Ele combina busca semÃ¢ntica (`sentence-transformers`) com a capacidade de raciocÃ­nio do **DeepSeek-R1** para estruturar informaÃ§Ãµes mÃ©dicas sem enviar dados sensÃ­veis para a nuvem.
